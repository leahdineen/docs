---
title: 'Get Evaluation Feedback'
api: 'GET /feedback/evaluation/{evaluation_id}'
description: 'Retrieve feedback submitted for an evaluation'
---

## Overview

Retrieves all feedback that has been submitted for a specific evaluation. This includes user corrections, ratings, and comments that help improve judge accuracy and performance.

## Path Parameters

<ParamField path="evaluation_id" type="string" required>
  Unique identifier of the evaluation
</ParamField>

## Query Parameters

<ParamField query="feedback_type" type="string">
  Filter feedback by type
  - `correction` - Corrective feedback
  - `rating` - Rating feedback
  - `comment` - General comments
  - `approval` - Approval/rejection feedback
</ParamField>

<ParamField query="include_metadata" type="boolean" default="true">
  Include feedback metadata (timestamps, user info)
</ParamField>

<ParamField query="limit" type="integer" default="50" min="1" max="200">
  Maximum number of feedback entries to return
</ParamField>

<ParamField query="offset" type="integer" default="0" min="0">
  Number of feedback entries to skip
</ParamField>

## Response

<ResponseField name="evaluation_id" type="string" required>
  ID of the evaluation
</ResponseField>

<ResponseField name="total_feedback_count" type="integer" required>
  Total number of feedback entries
</ResponseField>

<ResponseField name="feedback_summary" type="object" required>
  Summary of feedback statistics
  
  <Expandable title="summary properties">
    <ResponseField name="average_rating" type="number">
      Average rating score (if rating feedback exists)
    </ResponseField>
    
    <ResponseField name="correction_count" type="integer" required>
      Number of correction feedback entries
    </ResponseField>
    
    <ResponseField name="approval_count" type="integer" required>
      Number of approval feedback entries
    </ResponseField>
    
    <ResponseField name="rejection_count" type="integer" required>
      Number of rejection feedback entries
    </ResponseField>
    
    <ResponseField name="comment_count" type="integer" required>
      Number of comment feedback entries
    </ResponseField>
  </Expandable>
</ResponseField>

<ResponseField name="feedback_entries" type="array" required>
  List of feedback entries
  
  <Expandable title="feedback entry properties">
    <ResponseField name="feedback_id" type="string" required>
      Unique feedback identifier
    </ResponseField>
    
    <ResponseField name="type" type="string" required>
      Type of feedback (correction, rating, comment, approval)
    </ResponseField>
    
    <ResponseField name="content" type="object" required>
      Feedback content (varies by type)
      
      <Expandable title="content properties (varies by type)">
        <ResponseField name="corrected_scores" type="object">
          For corrections: corrected criterion scores
        </ResponseField>
        
        <ResponseField name="rating" type="number">
          For ratings: numerical rating (1-10)
        </ResponseField>
        
        <ResponseField name="comment" type="string">
          For comments: text comment
        </ResponseField>
        
        <ResponseField name="approved" type="boolean">
          For approval: whether evaluation was approved
        </ResponseField>
        
        <ResponseField name="explanation" type="string">
          Explanation for the feedback
        </ResponseField>
      </Expandable>
    </ResponseField>
    
    <ResponseField name="criterion_specific" type="boolean" required>
      Whether feedback applies to specific criteria
    </ResponseField>
    
    <ResponseField name="target_criteria" type="array">
      Criteria IDs this feedback targets (if criterion_specific=true)
    </ResponseField>
    
    <ResponseField name="submitted_by" type="string">
      User ID who submitted feedback (if include_metadata=true)
    </ResponseField>
    
    <ResponseField name="submitted_at" type="datetime" required>
      Feedback submission timestamp
    </ResponseField>
    
    <ResponseField name="processed" type="boolean" required>
      Whether feedback has been processed for training
    </ResponseField>
    
    <ResponseField name="processing_notes" type="string">
      Notes from feedback processing
    </ResponseField>
  </Expandable>
</ResponseField>

<ResponseField name="evaluation_context" type="object" required>
  Context about the original evaluation
  
  <Expandable title="context properties">
    <ResponseField name="judge_id" type="string" required>
      ID of the judge used
    </ResponseField>
    
    <ResponseField name="judge_version" type="integer" required>
      Version of the judge when evaluated
    </ResponseField>
    
    <ResponseField name="original_scores" type="object" required>
      Original evaluation scores
    </ResponseField>
    
    <ResponseField name="evaluation_date" type="datetime" required>
      When the evaluation was performed
    </ResponseField>
  </Expandable>
</ResponseField>

## Examples

<CodeGroup>

```bash Request
curl -X GET https://api.judge.example.com/feedback/evaluation/eval_abc123 \
  -H "Authorization: Bearer YOUR_API_KEY"
```

```json Success Response (200)
{
  "evaluation_id": "eval_abc123",
  "total_feedback_count": 3,
  "feedback_summary": {
    "average_rating": 7.5,
    "correction_count": 1,
    "approval_count": 1,
    "rejection_count": 1,
    "comment_count": 2
  },
  "feedback_entries": [
    {
      "feedback_id": "fb_001",
      "type": "correction",
      "content": {
        "corrected_scores": {
          "crit_clarity": 85,
          "crit_accuracy": 90
        },
        "explanation": "The accuracy score should be higher based on factual content"
      },
      "criterion_specific": true,
      "target_criteria": ["crit_clarity", "crit_accuracy"],
      "submitted_by": "user_123",
      "submitted_at": "2024-01-15T11:00:00Z",
      "processed": true,
      "processing_notes": "Used in retraining batch RT-2024-001"
    },
    {
      "feedback_id": "fb_002",
      "type": "rating",
      "content": {
        "rating": 8,
        "comment": "Good evaluation overall, minor issues with scoring"
      },
      "criterion_specific": false,
      "submitted_by": "user_456",
      "submitted_at": "2024-01-15T11:15:00Z",
      "processed": false
    },
    {
      "feedback_id": "fb_003",
      "type": "approval",
      "content": {
        "approved": false,
        "explanation": "Evaluation missed key quality indicators"
      },
      "criterion_specific": false,
      "submitted_by": "user_789",
      "submitted_at": "2024-01-15T11:30:00Z",
      "processed": true,
      "processing_notes": "Flagged for judge review"
    }
  ],
  "evaluation_context": {
    "judge_id": "jdg_xyz789",
    "judge_version": 2,
    "original_scores": {
      "overall_score": 78,
      "crit_clarity": 75,
      "crit_accuracy": 80
    },
    "evaluation_date": "2024-01-15T10:30:00Z"
  }
}
```

</CodeGroup>

<CodeGroup>

```bash Request: Filter by Feedback Type
curl -X GET "https://api.judge.example.com/feedback/evaluation/eval_abc123?feedback_type=correction" \
  -H "Authorization: Bearer YOUR_API_KEY"
```

```json Filtered Response (200)
{
  "evaluation_id": "eval_abc123",
  "total_feedback_count": 1,
  "feedback_summary": {
    "correction_count": 1,
    "approval_count": 0,
    "rejection_count": 0,
    "comment_count": 0
  },
  "feedback_entries": [
    {
      "feedback_id": "fb_001",
      "type": "correction",
      "content": {
        "corrected_scores": {
          "crit_clarity": 85,
          "crit_accuracy": 90
        },
        "explanation": "The accuracy score should be higher based on factual content"
      },
      "criterion_specific": true,
      "target_criteria": ["crit_clarity", "crit_accuracy"],
      "submitted_by": "user_123",
      "submitted_at": "2024-01-15T11:00:00Z",
      "processed": true,
      "processing_notes": "Used in retraining batch RT-2024-001"
    }
  ],
  "evaluation_context": {
    "judge_id": "jdg_xyz789",
    "judge_version": 2,
    "original_scores": {
      "overall_score": 78,
      "crit_clarity": 75,
      "crit_accuracy": 80
    },
    "evaluation_date": "2024-01-15T10:30:00Z"
  }
}
```

</CodeGroup>

<CodeGroup>

```bash Error: Evaluation Not Found
curl -X GET https://api.judge.example.com/feedback/evaluation/eval_invalid \
  -H "Authorization: Bearer YOUR_API_KEY"
```

```json Error Response (404)
{
  "error": {
    "code": "EVALUATION_NOT_FOUND",
    "message": "Evaluation with ID 'eval_invalid' not found or access denied"
  }
}
```

</CodeGroup>