---
title: 'Get OpenAI Configuration'
api: 'GET /config/openai'
description: 'Retrieve OpenAI integration settings'
---

## Overview

Retrieves the current OpenAI configuration settings for your organization, including API endpoints, model preferences, and usage limits.

## Response

<ResponseField name="api_endpoint" type="string" required>
  OpenAI API endpoint URL
</ResponseField>

<ResponseField name="default_model" type="string" required>
  Default model for evaluations (e.g., "gpt-4", "gpt-3.5-turbo")
</ResponseField>

<ResponseField name="max_tokens" type="integer" required>
  Maximum tokens per request
</ResponseField>

<ResponseField name="temperature" type="number" required>
  Default temperature setting (0.0 to 2.0)
</ResponseField>

<ResponseField name="rate_limits" type="object" required>
  Rate limiting configuration
  
  <Expandable title="rate limits">
    <ResponseField name="requests_per_minute" type="integer" required>
      Maximum requests per minute
    </ResponseField>
    
    <ResponseField name="tokens_per_minute" type="integer" required>
      Maximum tokens per minute
    </ResponseField>
  </Expandable>
</ResponseField>

<ResponseField name="fallback_models" type="array">
  Alternative models to use if primary fails
</ResponseField>

<ResponseField name="last_updated" type="datetime" required>
  Configuration last update timestamp
</ResponseField>

## Examples

<CodeGroup>

```bash Request
curl -X GET https://api.judge.example.com/config/openai \
  -H "Authorization: Bearer YOUR_API_KEY"
```

```json Success Response (200)
{
  "api_endpoint": "https://api.openai.com/v1",
  "default_model": "gpt-4",
  "max_tokens": 4096,
  "temperature": 0.3,
  "rate_limits": {
    "requests_per_minute": 60,
    "tokens_per_minute": 150000
  },
  "fallback_models": ["gpt-3.5-turbo", "gpt-3.5-turbo-16k"],
  "last_updated": "2024-01-15T10:00:00Z"
}
```

</CodeGroup>